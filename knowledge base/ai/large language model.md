# Large language model

_Language models_ are computational model that can predict sequences in natural language.<br/>
Useful for speech recognition, machine translation, natural language generation, optical character recognition, route
optimization, handwriting recognition, grammar induction, information retrieval, and other tasks.

_Large_ language models are predominantly based on transformers trained on large datasets, frequently including texts
scraped from the Internet.<br/>
They have superseded recurrent neural network-based models.

<!-- Remove this line to uncomment if used
## Table of contents <!-- omit in toc -->

1. [TL;DR](#tldr)
1. [Run LLMs Locally](#run-llms-locally)
1. [Further readings](#further-readings)
   1. [Sources](#sources)

## TL;DR

| FIXME     | Creator    |
| --------- | ---------- |
| [ChatGPT] | OpenAI     |
| [Claude]  | Anthropic  |
| [Copilot] | Microsoft  |
| [Duck AI] | DuckDuckGo |
| [Gemini]  | Google     |
| [Grok]    | X          |
| [Llama]   | Meta       |
| [Mistral] | Mistral AI |

<!-- Uncomment if used
<details>
  <summary>Setup</summary>

```sh
```

</details>
-->

<!-- Uncomment if used
<details>
  <summary>Usage</summary>

```sh
```

</details>
-->

<!-- Uncomment if used
<details>
  <summary>Real world use cases</summary>

```sh
```

</details>
-->

## Run LLMs Locally

Use one of the following:

- [Ollama]
- [LMStudio]
- [vLLM]
- [Jan]
- [llama.cpp]
- [Llamafile]

## Further readings

### Sources

- [Run LLMs Locally: 6 Simple Methods]

<!--
  Reference
  ═╬═Time══
  -->

<!-- In-article sections -->
<!-- Knowledge base -->
[LMStudio]: lmstudio.md
[Ollama]: ollama.md
[vLLM]: vllm.md

<!-- Files -->
<!-- Upstream -->
<!-- Others -->
[ChatGPT]: https://chatgpt.com/
[Claude]: https://claude.ai/
[Copilot]: https://copilot.microsoft.com/
[Duck AI]: https://duck.ai/
[Gemini]: https://gemini.google.com/
[Grok]: https://grok.com/
[Jan]: https://www.jan.ai/
[llama.cpp]: https://github.com/ggml-org/llama.cpp
[Llama]: https://www.llama.com/
[Llamafile]: https://github.com/mozilla-ai/llamafile
[Mistral]: https://mistral.ai/
[Run LLMs Locally: 6 Simple Methods]: https://www.datacamp.com/tutorial/run-llms-locally-tutorial
